{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b92d672a-a1ff-4806-9dce-5f8c9a4f051b",
      "metadata": {
        "name": "cell1",
        "codeCollapsed": true
      },
      "source": "# Water Quality Prediction: Benchmark Notebook "
    },
    {
      "cell_type": "markdown",
      "id": "173e8dca-8e21-478c-b9d8-8162214025ef",
      "metadata": {
        "name": "cell2",
        "codeCollapsed": true
      },
      "source": "## Challenge Overview"
    },
    {
      "cell_type": "markdown",
      "id": "0d38782b-973e-4f63-83b3-3e556abae629",
      "metadata": {
        "name": "cell3",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Welcome to the EY AI & Data Challenge 2026!  \nThe objective of this challenge is to build a robust **machine learning model** capable of predicting water quality across various river locations in South Africa. In addition to accurate predictions, the model should also identify and emphasize the key factors that significantly influence water quality.\n\nParticipants will be provided with a dataset containing three water quality parameters — **Total Alkalinity**, **Electrical Conductance**, and **Dissolved Reactive Phosphorus** — collected between 2011 and 2015 from approximately 200 river locations across South Africa. Each data point includes the geographic coordinates (latitude and longitude) of the sampling site, the date of collection, and the corresponding water quality measurements.\n\nUsing this dataset, participants are expected to build a machine learning model to predict water quality parameters for a separate validation dataset, which includes locations from different regions not present in the training data. The challenge also encourages participants to explore feature importance and provide insights into the factors most strongly associated with variations in water quality.\n\nThis challenge is designed for participants with varying levels of experience in data science, remote sensing, and environmental analytics. It offers a valuable opportunity to apply machine learning techniques to real-world environmental data and contribute to advancing water quality monitoring using artificial intelligence."
    },
    {
      "cell_type": "markdown",
      "id": "1ea5ca99-0ab8-4117-8bf1-991714e656be",
      "metadata": {
        "name": "cell4",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "**About the Notebook:**  "
    },
    {
      "cell_type": "markdown",
      "id": "86be35cd-7ec3-4697-b476-efb378803e53",
      "metadata": {
        "name": "cell5",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "In this notebook, we demonstrate a basic workflow that serves as a foundation for the challenge. The model has been developed to predict **water quality parameters** using features derived from the **Landsat** and **TerraClimate** datasets. Specifically, four spectral bands — **SWIR22** (Shortwave Infrared 2), **NIR** (Near Infrared), **Green**, and **SWIR16** (Shortwave Infrared 1) — were utilized from Landsat, along with derived spectral indices such as **NDMI** (Normalized Difference Moisture Index) and **MNDWI** (Modified Normalized Difference Water Index). In addition, the **PET** (Potential Evapotranspiration) variable was incorporated from the **TerraClimate** dataset to account for climatic influences on water quality.\n\nThe dataset spans a five-year period from **2011 to 2015**. Using **API-based data extraction** methods, both Landsat and TerraClimate features were retrieved directly from the [Microsoft Planetary Computer portal](https://planetarycomputer.microsoft.com).\n\nThese combined spectral, index-based, and climatic features were used as predictors in a regression model to estimate three key water quality parameters: **Total Alkalinity (TA)**, **Electrical Conductance (EC)**, and **Dissolved Reactive Phosphorus (DRP)**.\n\nPlease note that this notebook serves only as a starting point. Several assumptions were made during the data extraction and model development process, which you may find opportunities to improve upon. Participants are encouraged to explore additional features, enhance preprocessing techniques, or experiment with different regression algorithms to optimize predictive performance."
    },
    {
      "cell_type": "markdown",
      "id": "57447c9d-ceca-4a26-8066-2dca61e0e224",
      "metadata": {
        "name": "cell6",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Load In Dependencies\nThe following code installs the required Python libraries (found in the requirements.txt file) in the Snowflake environment to allow successful execution of the remaining notebook code. After running this code for the first time, it is required to “restart” the kernal so the Python libraries are available in the environment. This is done by selecting the “Connected” menu above the notebook (next to “Run all”) and selecting the “restart kernal” link. Subsequent runs of the notebook do not require this “restart” process."
    },
    {
      "cell_type": "code",
      "id": "7d7871c0-d5f3-45da-a289-3d19db67bf15",
      "metadata": {
        "language": "python",
        "name": "cell58"
      },
      "source": "!pip install uv\n!uv pip install -r requirements.txt xgboost",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "b53ef74f-52ba-4c63-b412-2f4432408d04",
      "metadata": {
        "language": "python",
        "name": "cell8",
        "codeCollapsed": false
      },
      "source": "import snowflake\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\n# Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Visualization libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Data manipulation and analysis\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display\n\n# Multi-dimensional arrays and datasets (e.g., NetCDF, Zarr)\nimport xarray as xr\n\n# Geospatial raster data handling with CRS support\nimport rioxarray as rxr\n\n# Raster operations and spatial windowing\nimport rasterio\nfrom rasterio.windows import Window\n\n# Feature preprocessing and data splitting\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, GroupKFold, RandomizedSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom scipy.spatial import cKDTree\nfrom scipy.stats import uniform, randint\n\n# Machine Learning\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error, make_scorer\n\n# Planetary Computer tools for STAC API access and authentication\nimport pystac_client\nimport planetary_computer as pc\nfrom odc.stac import stac_load\nfrom pystac.extensions.eo import EOExtension as eo\n\nfrom datetime import date\nfrom tqdm import tqdm\nimport os",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "fdfcbb20-8dff-401a-9f55-ed5d08eb6b60",
      "metadata": {
        "name": "cell9",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Response Variable"
    },
    {
      "cell_type": "markdown",
      "id": "401e1bce-f161-4d24-9f6b-a60778c39585",
      "metadata": {
        "name": "cell10",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Before building the model, we first load the **water quality training dataset**. The curated dataset contains samples collected from various monitoring stations across the study region. Each record includes the geographical coordinates (Latitude and Longitude), the sample collection date, and the corresponding **measured values** for the three key water quality parameters — **Total Alkalinity (TA)**, **Electrical Conductance (EC)**, and **Dissolved Reactive Phosphorus (DRP)**."
    },
    {
      "cell_type": "code",
      "id": "892acc46-4840-489a-8c69-ecf4123d2a31",
      "metadata": {
        "language": "python"
      },
      "source": "Water_Quality_df = pd.read_csv(\"water_quality_training_dataset.csv\")\ndisplay(Water_Quality_df.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "1ac87b43-019d-4aa4-bb4b-62b40cc6cda2",
      "metadata": {
        "name": "cell12",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Predictor Variables"
    },
    {
      "cell_type": "markdown",
      "id": "459bbd80-887c-4c1f-83f4-3d31ffc40551",
      "metadata": {
        "name": "cell13",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Now that we have our water quality dataset, the next step is to gather the predictor variables from the **Landsat** and **TerraClimate** datasets. In this notebook, we demonstrate how to **load previously extracted satellite and climate data** from separate files, rather than performing the extraction directly, which allows for a smoother and faster experience. Participants can refer to the dedicated extraction notebooks—one for Landsat and another for TerraClimate—to understand how the data was retrieved and processed, and they can also generate their own output CSV files if needed. Using these pre-extracted CSV files, this notebook focuses on loading the predictor features and running the subsequent analysis and model training efficiently.\n\nFor more detailed guidance on the original data extraction process, you can review the Landsat and TerraClimate example notebooks available on the Planetary Computer portal:\n\n- [Landsat-c2-l2 - Example-Notebook](https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2#Example-Notebook)  \n- [Terraclimate - Example-Notebook](https://planetarycomputer.microsoft.com/dataset/terraclimate#Example-Notebook)\n\nWe have used selected spectral bands — **SWIR22** (Shortwave Infrared 2), **NIR** (Near Infrared), **Green**, and **SWIR16** (Shortwave Infrared 1) — and computed key spectral indices such as **NDMI** (Normalized Difference Moisture Index) and **MNDWI** (Modified Normalized Difference Water Index). These features capture surface moisture, vegetation, and water content characteristics that influence water quality variability.\n\nIn addition to Landsat features, we also incorporated the **Potential Evapotranspiration (PET)** variable from the **TerraClimate** dataset, which provides high-resolution global climate data. The PET feature captures the atmospheric demand for moisture, representing climatic conditions such as temperature, humidity, and radiation that influence surface water evaporation and thus affect water quality parameters.\n\nThe predictor features include:\n\n- **SWIR22** – Sensitive to surface moisture and turbidity variations in water bodies.  \n- **NIR** – Helps in identifying vegetation and suspended matter in water.  \n- **Green** – Useful for detecting water color and surface reflectance changes.  \n- **SWIR16** – Provides information on surface dryness and sediment concentration.  \n- **NDMI** – Derived from NIR and SWIR16, indicates moisture and vegetation–water interaction.  \n- **MNDWI** – Derived from Green and SWIR22, effective for distinguishing open water areas and reducing built-up noise.  \n- **PET** – Extracted from the TerraClimate dataset, represents potential evapotranspiration influencing hydrological and water quality dynamics."
    },
    {
      "cell_type": "markdown",
      "id": "cced81f1-3b77-4a69-ac48-9d02cc12c647",
      "metadata": {
        "name": "cell14",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### **Tip 1**\n\nParticipants are encouraged to experiment with different combinations of **Landsat** bands or even include data from other public satellite data sources. By creating mathematical combinations of bands, you can derive various spectral indices that capture surface and environmental characteristics."
    },
    {
      "cell_type": "markdown",
      "id": "83a0c7e8-9471-4a09-9ac4-6a5b5f0703bd",
      "metadata": {
        "name": "cell15",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Loading Pre-Extracted Landsat Data\n\nIn this notebook, we **load previously extracted Landsat data** from CSV files generated in a separate extraction notebook. This approach ensures a smoother and faster workflow, allowing participants to focus on data analysis and model development without waiting for time-consuming data retrieval.\n\nParticipants are expected to generate their own data extraction CSV files by running the dedicated Landsat extraction notebook. These CSV files can then be used here to smoothly run this benchmark notebook. Participants can refer to the extraction notebook to understand the API-based process, including how individual bands and indices like **NDMI** were computed. Using these pre-extracted CSV files simplifies preprocessing and is ideal for large-scale environmental and water quality analysis."
    },
    {
      "cell_type": "markdown",
      "id": "bfe34327-f165-452c-98ef-3df67b6ed550",
      "metadata": {
        "name": "cell16",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### **Tip 2**\n\nIn the data extraction process (performed in the dedicated extraction notebooks), a 100 m focal buffer was applied around each sampling location rather than using a single point. Participants may explore creating different focal buffers around the locations (e.g., 50 m, 150 m, etc.) during extraction. For example, if a 50 m buffer was used for “Band 2”, the extracted CSV values would reflect the average of Band 2 within 50 meters of each location. This approach can help reduce errors associated with spatial autocorrelation."
    },
    {
      "cell_type": "code",
      "id": "5c250c49-d6ed-42f7-ad90-b2f619de0027",
      "metadata": {
        "language": "python"
      },
      "source": "landsat_train_features = pd.read_csv(\"landsat_features_training.csv\")\ndisplay(landsat_train_features.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "61676d8d-7141-4682-9687-850e56e3ef28",
      "metadata": {
        "language": "python"
      },
      "source": "# If NDMI and MNDWI columns are of type object, convert them to float\nlandsat_train_features['NDMI'] = landsat_train_features['NDMI'].astype(float)\nlandsat_train_features['MNDWI'] = landsat_train_features['MNDWI'].astype(float)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "8ce0ed5d-32c0-48f9-863c-ef84bad110d2",
      "metadata": {
        "name": "cell18",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Loading Pre-Extracted TerraClimate Data\n\nIn this notebook, we **load previously extracted TerraClimate data** from CSV files generated in a dedicated extraction notebook. This approach ensures a smoother and faster workflow, allowing participants to focus on data analysis and model development without waiting for time-consuming data retrieval.\n\nParticipants are expected to generate their own data extraction CSV files by running the dedicated TerraClimate extraction notebook. These CSV files can then be used here to smoothly run this benchmark notebook. Participants can refer to the extraction notebook to understand the API-based process, including how climate variables such as **Potential Evapotranspiration (PET)** were extracted. Using these pre-extracted CSV files ensures consistent, automated retrieval of high-resolution climate data that can be easily integrated with satellite-derived features for comprehensive environmental and hydrological analysis."
    },
    {
      "cell_type": "code",
      "id": "1862bd48-8134-477a-bcf5-314ac04b2048",
      "metadata": {
        "language": "python"
      },
      "source": "Terraclimate_df = pd.read_csv(\"terraclimate_features_training.csv\")\ndisplay(Terraclimate_df.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "475de826-a08c-4ea1-bbfc-5e9a3240ab22",
      "metadata": {
        "name": "cell20",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Joining the Predictor Variables and Response Variables\n\nNow that we have extracted our predictor variables, we need to join them with the response variables. We use the **combine_two_datasets** function to merge the predictor variables and response variables. The **concat** function from pandas is particularly useful for this step."
    },
    {
      "cell_type": "code",
      "id": "7b42801e-e7b9-4b17-b4e4-f65fd971decc",
      "metadata": {
        "language": "python",
        "name": "cell21"
      },
      "source": "# Combine two datasets vertically (along columns) using pandas concat function.\ndef combine_two_datasets(dataset1,dataset2,dataset3):\n    '''\n    Returns a  vertically concatenated dataset.\n    Attributes:\n    dataset1 - Dataset 1 to be combined \n    dataset2 - Dataset 2 to be combined\n    '''\n    \n    data = pd.concat([dataset1,dataset2,dataset3], axis=1)\n    data = data.loc[:, ~data.columns.duplicated()]\n    return data",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c75dffde-a8e3-4a6e-bbab-bf0d8aac7bfe",
      "metadata": {
        "language": "python",
        "name": "cell22",
        "codeCollapsed": false
      },
      "source": "# Combining ground data and final data into a single dataset.\nwq_data = combine_two_datasets(Water_Quality_df, landsat_train_features, Terraclimate_df)\ndisplay(wq_data.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "c4573656-100c-49e7-b3bb-536e0a6290ac",
      "metadata": {
        "name": "cell23",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Handling Missing Values\n\nBefore model training, missing values in the dataset were carefully handled to ensure data consistency and prevent model bias. Numerical columns were imputed using their median values, maintaining the overall data distribution while minimizing the impact of outliers."
    },
    {
      "cell_type": "code",
      "id": "de7372e4-26c6-4bd8-9d7a-39bc35b01a14",
      "metadata": {
        "language": "python",
        "name": "cell24"
      },
      "source": "# 1. Filtrar nuvens (valores muito altos indicam contaminação por nuvens)\nfor col in ['nir', 'green', 'swir16', 'swir22']:\n    wq_data[col] = wq_data[col].where(wq_data[col] < 50000, np.nan)\n\n# Preencher valores ausentes com a mediana\nwq_data = wq_data.fillna(wq_data.median(numeric_only=True))\nwq_data.isna().sum()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "560a997d-ec88-4ae0-b540-44cd3e5f6cf2",
      "metadata": {
        "name": "cell25",
        "codeCollapsed": true
      },
      "source": "## Model Building"
    },
    {
      "cell_type": "markdown",
      "id": "8e9f7c65-b3a1-405b-b912-cef4e5157bce",
      "metadata": {
        "name": "cell26",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "We now use **all 7 available features** — the 4 Landsat bands (**NIR**, **Green**, **SWIR16**, **SWIR22**), the 2 derived indices (**NDMI**, **MNDWI**), and **PET** from TerraClimate. The benchmark only used 4, discarding NIR, Green, and SWIR16.\n\nWe also apply a **log1p transform** to the target variables before training. Water quality parameters are right-skewed and span wide ranges, so modeling in log-space helps XGBoost learn more stable patterns. Predictions are reverted with `expm1` before submission."
    },
    {
      "cell_type": "code",
      "id": "35381365-adf1-4702-a99d-5cec95812ff9",
      "metadata": {
        "language": "python",
        "name": "cell27"
      },
      "source": "# 2. Novas features\nwq_data['month_sin'] = np.sin(2 * np.pi * pd.to_datetime(wq_data['Sample Date'], dayfirst=True).dt.month / 12)\nwq_data['month_cos'] = np.cos(2 * np.pi * pd.to_datetime(wq_data['Sample Date'], dayfirst=True).dt.month / 12)\nwq_data['year']      = pd.to_datetime(wq_data['Sample Date'], dayfirst=True).dt.year\nwq_data['NIR_SWIR22_ratio'] = wq_data['nir'] / (wq_data['swir22'] + 1e-6)\nwq_data['turbidity']        = wq_data['swir16'] / (wq_data['green'] + 1e-6)\n\n# All features (original 7 + 5 novas)\nFEATURE_COLS = [\n    'nir', 'green', 'swir16', 'swir22', 'NDMI', 'MNDWI', 'pet',\n    'month_sin', 'month_cos', 'year',\n    'NIR_SWIR22_ratio', 'turbidity'\n]\n\nwq_data = wq_data[['Latitude', 'Longitude'] + FEATURE_COLS +\n                   ['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']]",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "f56f994c-0b88-4d19-8426-3fb73c71e2b5",
      "metadata": {
        "name": "cell28",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### **Tip 3**\n\nWe are developing individual models for each water quality parameter using a common set of features: **SWIR22**, **NDMI**, **MNDWI**, and **PET**. However, participants are encouraged to experiment with different feature combinations to build more robust machine learning models."
    },
    {
      "cell_type": "markdown",
      "id": "1e241de9-35e2-4fa6-9bba-2d5456af838a",
      "metadata": {
        "name": "cell29",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Helper Functions\n\n### Pipeline with StandardScaler + XGBoost\nWe use a scikit-learn `Pipeline` that wraps the `StandardScaler` and the `XGBRegressor` into a single object. This **prevents data leakage** because the scaler is fitted only on the training data of each fold during cross-validation, never seeing the validation data.\n\n### GroupKFold by Location\nInstead of a simple random split, we use **GroupKFold** grouping by geographic location (combination of Latitude and Longitude). This ensures that **all samples from the same monitoring station stay in the same fold**, simulating real spatial evaluation — the model is evaluated on locations it has never seen during training.\n\nThe locations (Latitude, Longitude) are used only to define the fold splits during GroupKFold — they are not used as input features to the model.\n\nSo, the groups parameter tells GroupKFold which rows belong together (same station), but the model itself only ever sees swir22, NDMI, MNDWI, and pet. The groups ensure that during hyperparameter tuning, no fold leaks data from a station it's supposed to evaluate on — but the trained model has no knowledge of coordinates.\n\nAt final prediction time, pipeline_TA.predict(submission_val_data) receives only ['swir22', 'NDMI', 'MNDWI', 'pet'] — no location information at all.\n\n### RandomizedSearchCV for Hyperparameter Tuning\nWe use `RandomizedSearchCV` to efficiently search for the best XGBoost hyperparameters by sampling random combinations from the search space. This is faster than an exhaustive `GridSearchCV` and generally finds good configurations with fewer iterations.\n\n### Model Evaluation\nAfter tuning, we evaluate the best model found using:\n- **R² Score**: Measures how well the model explains the variance in the observed values.\n- **RMSE (Root Mean Square Error)**: Quantifies the average magnitude of prediction errors."
    },
    {
      "cell_type": "markdown",
      "id": "ad8e06d5-10a6-419a-b096-52c6f0566e1f",
      "metadata": {
        "name": "cell30",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### **Tip 4**\n\nThere are many data preprocessing methods available that may help improve model performance. Participants are encouraged to explore various preprocessing techniques as well as different machine learning algorithms to build a more robust model."
    },
    {
      "cell_type": "code",
      "id": "c7e68f6e-1679-467f-803c-e819d654bbab",
      "metadata": {
        "language": "python",
        "name": "cell31"
      },
      "source": "def create_location_groups(wq_data):\n    \"\"\"Create group labels based on unique (Latitude, Longitude) pairs for GroupKFold.\"\"\"\n    groups = wq_data[['Latitude', 'Longitude']].apply(lambda row: f\"{row['Latitude']}_{row['Longitude']}\", axis=1)\n    return groups\n\ndef build_pipeline():\n    \"\"\"Build a Pipeline with StandardScaler + XGBRegressor (avoids data leakage).\"\"\"\n    pipeline = Pipeline([\n        ('scaler', StandardScaler()),\n        ('model', XGBRegressor(\n            objective='reg:squarederror',\n            random_state=42,\n            n_jobs=-1,\n            verbosity=0\n        ))\n    ])\n    return pipeline\n\ndef get_xgb_param_distributions():\n    \"\"\"Define hyperparameter search space for XGBoost.\"\"\"\n    param_distributions = {\n        'model__n_estimators':      randint(200, 800),\n        'model__max_depth':         [4, 6, 8],       # mínimo 4, não 3\n        'model__learning_rate':     uniform(0.05, 0.15),  # 0.05 a 0.20\n        'model__subsample':         uniform(0.6, 0.4),\n        'model__colsample_bytree':  uniform(0.6, 0.4),\n        'model__min_child_weight':  [1, 2, 3],        # máximo 3\n        'model__reg_alpha':         [0, 0.01, 0.1],   # quase zero\n        'model__reg_lambda':        [0.5, 1.0, 1.5],  # padrão é 1\n        'model__gamma':             [0, 0.01, 0.05],  # quase zero\n    }\n    return param_distributions\n\ndef evaluate_predictions(y_true, y_pred, dataset_name=\"Test\"):\n    \"\"\"Evaluate predictions with R² and RMSE.\"\"\"\n    r2 = r2_score(y_true, y_pred)\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    print(f\"\\n{dataset_name} Evaluation:\")\n    print(f\"  R²:   {r2:.4f}\")\n    print(f\"  RMSE: {rmse:.4f}\")\n    return r2, rmse",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "39cec372-283e-404a-a989-714969c53b0d",
      "metadata": {
        "name": "cell32",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Model Workflow (Pipeline)\n\nThe complete pipeline follows a robust structure to ensure **reproducibility**, **no data leakage**, and **realistic spatial evaluation**:\n\n1. **Location-based group creation** — each unique (Latitude, Longitude) combination receives a group label.\n2. **GroupKFold (5 folds)** — ensures that samples from the same station never appear simultaneously in training and validation.\n3. **Pipeline (StandardScaler → XGBRegressor)** — the scaler is fitted only within each training fold.\n4. **RandomizedSearchCV** — explores 50 random hyperparameter combinations, evaluating each with GroupKFold.\n5. **Final evaluation** — the best model is refitted on all data and also evaluated via cross-validation scores."
    },
    {
      "cell_type": "code",
      "id": "40808f99-8014-4746-91ae-5b64c61e04a7",
      "metadata": {
        "language": "python",
        "name": "cell33"
      },
      "source": "def run_pipeline(X, y_log, groups, param_name=\"Parameter\", n_splits=5, n_iter=50):\n    print(f\"\\n{'='*60}\")\n    print(f\"Training Model for {param_name}\")\n    print(f\"{'='*60}\")\n    \n    group_kfold = GroupKFold(n_splits=n_splits)\n    pipeline = build_pipeline()\n    param_distributions = get_xgb_param_distributions()\n    \n    # Scorers that convert back to original scale before computing metrics\n    rmse_scorer = make_scorer(\n        lambda y_true, y_pred: np.sqrt(mean_squared_error(np.expm1(y_true), np.expm1(y_pred))),\n        greater_is_better=False\n    )\n    r2_scorer = make_scorer(\n        lambda y_true, y_pred: r2_score(np.expm1(y_true), np.expm1(y_pred)),\n        greater_is_better=True\n    )\n    \n    search = RandomizedSearchCV(\n        estimator=pipeline,\n        param_distributions=param_distributions,\n        n_iter=n_iter,\n        cv=group_kfold,\n        scoring={'r2': r2_scorer, 'rmse': rmse_scorer},\n        refit='r2',\n        random_state=42,\n        n_jobs=-1,\n        verbose=1,\n        return_train_score=True\n    )\n    \n    search.fit(X, y_log, groups=groups)\n    \n    best_pipeline = search.best_estimator_\n    best_idx = search.best_index_\n    cv = search.cv_results_\n    \n    r2_train = cv['mean_train_r2'][best_idx]\n    r2_val   = cv['mean_test_r2'][best_idx]\n    rmse_train = -cv['mean_train_rmse'][best_idx]\n    rmse_val   = -cv['mean_test_rmse'][best_idx]\n    \n    print(f\"\\nBest Hyperparameters:\")\n    for param, value in search.best_params_.items():\n        print(f\"  {param}: {value}\")\n    \n    print(f\"\\nCross-Validation Results — Original Scale (GroupKFold, {n_splits} folds):\")\n    print(f\"  Train R²:  {r2_train:.4f}  |  Train RMSE: {rmse_train:.4f}\")\n    print(f\"  Val   R²:  {r2_val:.4f}  |  Val   RMSE: {rmse_val:.4f}\")\n    \n    results = {\n        \"Parameter\": param_name,\n        \"CV_R2_Train\": round(r2_train, 4),\n        \"CV_RMSE_Train\": round(rmse_train, 4),\n        \"CV_R2_Val\": round(r2_val, 4),\n        \"CV_RMSE_Val\": round(rmse_val, 4),\n    }\n    \n    return best_pipeline, pd.DataFrame([results])",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "1783a30e-ee66-4c50-a957-b67296e9328c",
      "metadata": {
        "name": "cell34",
        "codeCollapsed": true
      },
      "source": "### Model Training and Evaluation for Each Parameter"
    },
    {
      "cell_type": "markdown",
      "id": "ed5f39fd-a577-4eff-9fa5-caa9d7f2fcda",
      "metadata": {
        "name": "cell35",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "In this step, we apply the complete modeling pipeline to each of the three selected water quality parameters — Total Alkalinity, Electrical Conductance, and Dissolved Reactive Phosphorus. \n\n**Importantly**, we create **location-based groups** from the (Latitude, Longitude) pairs and pass them to `GroupKFold`, so the model is always validated on locations it has never seen during training. The `RandomizedSearchCV` explores 50 random hyperparameter combinations for XGBoost, evaluated across 5 spatial folds."
    },
    {
      "cell_type": "code",
      "id": "d2d5f62b-585c-45e0-8fa9-73a5fa1248f8",
      "metadata": {
        "language": "python",
        "name": "cell36"
      },
      "source": "# Create location-based groups for GroupKFold\ngroups = create_location_groups(wq_data)\nprint(f\"Total samples: {len(wq_data)}\")\nprint(f\"Unique locations (groups): {groups.nunique()}\")\n\n# Feature matrix — all 7 features\nX = wq_data[FEATURE_COLS]\n\n# Target variables with log1p transform (right-skewed → more stable training)\ny_TA_log = np.log1p(wq_data['Total Alkalinity'])\ny_EC_log = np.log1p(wq_data['Electrical Conductance'])\ny_DRP_log = np.log1p(wq_data['Dissolved Reactive Phosphorus'])\n\n# Run pipeline for each parameter (trained on log-space targets)\npipeline_TA, results_TA = run_pipeline(X, y_TA_log, groups, \"Total Alkalinity (log)\")\npipeline_EC, results_EC = run_pipeline(X, y_EC_log, groups, \"Electrical Conductance (log)\")\npipeline_DRP, results_DRP = run_pipeline(X, y_DRP_log, groups, \"Dissolved Reactive Phosphorus (log)\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "644a854c-a8af-411e-b5af-e78d064d80a1",
      "metadata": {
        "name": "cell37",
        "codeCollapsed": true
      },
      "source": "### Model Performance Summary"
    },
    {
      "cell_type": "markdown",
      "id": "23b4c7a8-c192-469f-8a18-972f4900da2b",
      "metadata": {
        "name": "cell38",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "The table below consolidates the **GroupKFold cross-validation** results for each water quality parameter. The training and validation metrics represent **averages across folds**, where each fold ensures complete spatial separation between training and validation stations."
    },
    {
      "cell_type": "code",
      "id": "c7f3a047-a05c-4369-8a84-5b287f1ff272",
      "metadata": {
        "language": "python",
        "name": "cell39"
      },
      "source": "results_summary = pd.concat([results_TA, results_EC, results_DRP], ignore_index=True)\nresults_summary",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "b5277b08-d7bc-4b7c-91bf-26fa19795f56",
      "metadata": {
        "name": "cell41",
        "codeCollapsed": true
      },
      "source": "## Submission (Test Set Predictions)\n\n**Naming clarification:** The provided CSV files use the word \"validation\" in their filenames (e.g., `landsat_features_validation.csv`), but these are actually the **test set** — we do **not** know the true labels. Our real validation happens internally via `GroupKFold` during training. Below, we rename variables to `test_*` for clarity."
    },
    {
      "cell_type": "code",
      "id": "1475b7c2-6562-4274-9bd6-98b305010351",
      "metadata": {
        "language": "python"
      },
      "source": "submission_template = pd.read_csv(\"submission_template.csv\")\ndisplay(submission_template.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "36e85fe2-7570-432e-b1f2-bc16dda08ab4",
      "metadata": {
        "language": "python"
      },
      "source": "landsat_test_features = pd.read_csv(\"landsat_features_validation.csv\")  # \"validation\" file = actual test set\ndisplay(landsat_test_features.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "48e53ead-e1b6-4d7d-93bb-12505fbb2ead",
      "metadata": {
        "language": "python"
      },
      "source": "terraclimate_test_df = pd.read_csv(\"terraclimate_features_validation.csv\")  # \"validation\" file = actual test set\ndisplay(terraclimate_test_df.head(5))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "d1dabb48-7f82-4acf-b509-21cc15a5a4e0",
      "metadata": {
        "language": "python",
        "name": "cell47",
        "codeCollapsed": false
      },
      "source": "# Consolidate test set features into a single dataframe\ntest_data = pd.DataFrame({\n    'Longitude': landsat_test_features['Longitude'].values,\n    'Latitude': landsat_test_features['Latitude'].values,\n    'Sample Date': landsat_test_features['Sample Date'].values,\n    'nir': landsat_test_features['nir'].values,\n    'green': landsat_test_features['green'].values,\n    'swir16': landsat_test_features['swir16'].values,\n    'swir22': landsat_test_features['swir22'].values,\n    'NDMI': landsat_test_features['NDMI'].values,\n    'MNDWI': landsat_test_features['MNDWI'].values,\n    'pet': terraclimate_test_df['pet'].values,\n})",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "5c41d268-0657-490b-94f3-8ffeb67c2265",
      "metadata": {
        "language": "python",
        "name": "cell48",
        "codeCollapsed": false
      },
      "source": "# Filtrar nuvens no test set (mesma lógica do treino)\nfor col in ['nir', 'green', 'swir16', 'swir22']:\n    test_data[col] = test_data[col].where(test_data[col] < 50000, np.nan)\n\n# Impute missing values in the test set\ntest_data = test_data.fillna(test_data.median(numeric_only=True))\n\n# Criar as mesmas features do treino\ntest_data['month_sin'] = np.sin(2 * np.pi * pd.to_datetime(test_data['Sample Date'], dayfirst=True).dt.month / 12)\ntest_data['month_cos'] = np.cos(2 * np.pi * pd.to_datetime(test_data['Sample Date'], dayfirst=True).dt.month / 12)\ntest_data['year']      = pd.to_datetime(test_data['Sample Date'], dayfirst=True).dt.year\ntest_data['NIR_SWIR22_ratio'] = test_data['nir'] / (test_data['swir22'] + 1e-6)\ntest_data['turbidity']        = test_data['swir16'] / (test_data['green'] + 1e-6)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "61202dd1-2587-4fed-9abb-9ffd77fce870",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Diagnóstico: verificar parsing de datas no test set\nprint(\"=== Sample Date (raw) ===\")\nprint(test_data['Sample Date'].head(10))\nprint(\"\\n=== Sample Date (parsed with dayfirst=True) ===\")\nprint(pd.to_datetime(test_data['Sample Date'], dayfirst=True).head(10))\nprint(\"\\n=== NaN count nas novas features ===\")\nprint(test_data[['month_sin', 'month_cos', 'year']].isna().sum())\nprint(\"\\n=== Estatísticas das novas features (test) ===\")\nprint(test_data[['month_sin', 'month_cos', 'year', 'NIR_SWIR22_ratio', 'turbidity']].describe())",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "3126bf77-fb54-4609-a09c-8e36b496d108",
      "metadata": {
        "language": "python",
        "name": "cell49",
        "codeCollapsed": false
      },
      "source": "# Select the same 7 features used during training\nX_test = test_data[FEATURE_COLS]\ndisplay(X_test.head())",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "d7b033c7-3d5f-4179-b8f8-182f8caad0dc",
      "metadata": {
        "language": "python",
        "name": "cell50",
        "codeCollapsed": false
      },
      "source": "X_test.shape",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "87b59132-ff14-421e-b37b-472a0adcd9da",
      "metadata": {
        "language": "python",
        "name": "cell51",
        "codeCollapsed": false
      },
      "source": "# Predict in log-space, then revert with expm1 to get original scale\npred_TA = np.expm1(pipeline_TA.predict(X_test))\npred_EC = np.expm1(pipeline_EC.predict(X_test))\npred_DRP = np.expm1(pipeline_DRP.predict(X_test))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "398e375c-60cc-4fa5-a697-ae12fdab300c",
      "metadata": {
        "language": "python",
        "name": "cell52",
        "codeCollapsed": false
      },
      "source": "submission_df = pd.DataFrame({\n    'Longitude': submission_template['Longitude'].values,\n    'Latitude': submission_template['Latitude'].values,\n    'Sample Date': submission_template['Sample Date'].values,\n    'Total Alkalinity': pred_TA,\n    'Electrical Conductance': pred_EC,\n    'Dissolved Reactive Phosphorus': pred_DRP\n})",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "46e1c4fa-e49f-40cf-ac10-729b82c4b37b",
      "metadata": {
        "language": "python",
        "name": "cell53",
        "codeCollapsed": false
      },
      "source": "#Displaying the sample submission dataframe\ndisplay(submission_df.head())",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "0d3a8c41-dba2-43e4-b84c-a50a096980e7",
      "metadata": {
        "language": "python",
        "name": "cell54",
        "codeCollapsed": false
      },
      "source": "#Dumping the predictions into a csv file.\nsubmission_df.to_csv(\"/tmp/submission.csv\",index = False)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "6bc2ba55-0dd6-43ab-902d-6adbfdfaca2c",
      "metadata": {
        "language": "python"
      },
      "source": "session.sql(\"\"\"\n    PUT file:///tmp/submission.csv\n    'snow://workspace/USER$.PUBLIC.\"ey-hackathon\"/versions/live/'\n    AUTO_COMPRESS=FALSE\n    OVERWRITE=TRUE\n\"\"\").collect()\nprint(\"File saved! Refresh the browser to see the files in the sidebar\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "9b7af545-7a55-4b59-9edc-bc43f47bffd5",
      "metadata": {
        "name": "cell55",
        "collapsed": false,
        "codeCollapsed": false
      },
      "source": "### Upload submission file on platform\n\nUpload the `submission.csv` file on the challenge platform to generate your score on the leaderboard."
    },
    {
      "cell_type": "markdown",
      "id": "b7ab09ba-3b69-4a2a-a56e-2dbf084e0c56",
      "metadata": {
        "name": "cell57",
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Conclusion\n\nNow that you have learned a basic approach to model training, it’s time to explore your own techniques and ideas! Feel free to modify any of the functions presented in this notebook to experiment with alternative preprocessing steps, feature engineering strategies, or machine learning algorithms. \n\nWe look forward to seeing your enhanced model and the insights you uncover. Best of luck with the challenge!"
    }
  ]
}