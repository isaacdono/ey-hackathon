{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da35050",
   "metadata": {},
   "source": [
    "# Water Quality Prediction — Submission Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d008edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uv\n",
    "!uv pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from scipy.stats import mstats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c2dfb0",
   "metadata": {},
   "source": [
    "## 1. Load & Merge Data (join by key, not by index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4ae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wq = pd.read_csv(\"water_quality_training_dataset.csv\")\n",
    "landsat = pd.read_csv(\"landsat_features_training.csv\")\n",
    "terra = pd.read_csv(\"terraclimate_features_training.csv\")\n",
    "\n",
    "# Merge by key — never by index\n",
    "JOIN_KEYS = ['Latitude', 'Longitude', 'Sample Date']\n",
    "df = wq.merge(landsat, on=JOIN_KEYS, how='left') \\\n",
    "       .merge(terra, on=JOIN_KEYS, how='left')\n",
    "\n",
    "print(f\"Shape after merge: {df.shape}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1523d",
   "metadata": {},
   "source": [
    "## 2. Landsat Calibration (DN → Reflectance) & Recalculate Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b64ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS = ['nir', 'green', 'swir16', 'swir22']\n",
    "\n",
    "def calibrate_landsat(data):\n",
    "    \"\"\"Apply Landsat C2L2 scale/offset to convert DN → surface reflectance.\"\"\"\n",
    "    scale, offset = 0.0000275, -0.2\n",
    "    for col in BANDS:\n",
    "        data[col] = data[col] * scale + offset\n",
    "    # Recalculate indices from calibrated reflectance\n",
    "    data['NDMI']  = (data['nir'] - data['swir16']) / (data['nir'] + data['swir16'])\n",
    "    data['MNDWI'] = (data['green'] - data['swir22']) / (data['green'] + data['swir22'])\n",
    "    return data\n",
    "\n",
    "df = calibrate_landsat(df)\n",
    "print(\"Calibrated reflectance ranges:\")\n",
    "for b in BANDS:\n",
    "    print(f\"  {b}: [{df[b].min():.4f}, {df[b].max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15b5e6d",
   "metadata": {},
   "source": [
    "## 3. Cloud Filter, Cluster-based Imputation & DRP Censoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee8ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud filter: after calibration, valid reflectance is roughly [0, 1.0]\n",
    "for col in BANDS:\n",
    "    df[col] = df[col].where(df[col].between(-0.05, 1.2), np.nan)\n",
    "\n",
    "# Cluster-based imputation (spatial, not global median)\n",
    "N_CLUSTERS = 8\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=10)\n",
    "df['geo_cluster'] = kmeans.fit_predict(df[['Latitude', 'Longitude']])\n",
    "\n",
    "impute_cols = BANDS + ['NDMI', 'MNDWI', 'pet']\n",
    "for col in impute_cols:\n",
    "    cluster_med = df.groupby('geo_cluster')[col].transform('median')\n",
    "    df[col] = df[col].fillna(cluster_med)\n",
    "# Fallback: global median for any remaining NaN\n",
    "train_medians = df[impute_cols].median()\n",
    "df[impute_cols] = df[impute_cols].fillna(train_medians)\n",
    "\n",
    "# DRP censoring: 10.0 = below detection limit → replace with DL/2\n",
    "df['Dissolved Reactive Phosphorus'] = df['Dissolved Reactive Phosphorus'].replace(10.0, 5.0)\n",
    "\n",
    "print(f\"Remaining NaNs:\\n{df.isna().sum()[df.isna().sum() > 0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64725f5",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.to_datetime(df['Sample Date'], dayfirst=True)\n",
    "df['month_sin'] = np.sin(2 * np.pi * dates.dt.month / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * dates.dt.month / 12)\n",
    "df['NIR_SWIR22_ratio'] = df['nir'] / (df['swir22'] + 1e-6)\n",
    "df['turbidity']        = df['swir16'] / (df['green'] + 1e-6)\n",
    "\n",
    "# KNN is distance-based: year creates artificial distance between identical\n",
    "# seasonal patterns and PET lags are mostly copies of pet (first obs fallback),\n",
    "# adding redundant dimensions that hurt KNN. Removed both.\n",
    "FEATURE_COLS = [\n",
    "    'nir', 'green', 'swir16', 'swir22',\n",
    "    'NDMI', 'MNDWI',\n",
    "    'pet',\n",
    "    'month_sin', 'month_cos',\n",
    "    'NIR_SWIR22_ratio', 'turbidity',\n",
    "]\n",
    "print(f\"Features ({len(FEATURE_COLS)}): {FEATURE_COLS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709338ab",
   "metadata": {},
   "source": [
    "## 5. Winsorize Targets & Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = ['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n",
    "\n",
    "# Winsorize extreme outliers before log transform (critical for KNN — outliers distort distances)\n",
    "for col in TARGETS:\n",
    "    df[col] = mstats.winsorize(df[col], limits=[0.01, 0.01])\n",
    "\n",
    "# Groups for spatial CV\n",
    "groups = df[['Latitude', 'Longitude']].apply(lambda r: f\"{r['Latitude']}_{r['Longitude']}\", axis=1)\n",
    "\n",
    "X = df[FEATURE_COLS]\n",
    "y_TA_log  = np.log1p(df['Total Alkalinity'])\n",
    "y_EC_log  = np.log1p(df['Electrical Conductance'])\n",
    "y_DRP_log = np.log1p(df['Dissolved Reactive Phosphorus'])\n",
    "\n",
    "print(f\"Samples: {len(X)} | Unique locations: {groups.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2e36d",
   "metadata": {},
   "source": [
    "## 6. Model Training (KNN + StandardScaler + GroupKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96cb571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(X, y_log, groups, param_name, n_splits=5):\n",
    "    print(f\"\\n{'='*60}\\nTraining: {param_name}\\n{'='*60}\")\n",
    "\n",
    "    group_kfold = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', KNeighborsRegressor(weights='distance', metric='euclidean'))\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [5, 7, 10, 15, 20, 30],\n",
    "        'model__p': [1, 2],  # 1=manhattan, 2=euclidean\n",
    "    }\n",
    "\n",
    "    rmse_scorer = make_scorer(\n",
    "        lambda yt, yp: np.sqrt(mean_squared_error(np.expm1(yt), np.expm1(yp))),\n",
    "        greater_is_better=False)\n",
    "    r2_scorer = make_scorer(\n",
    "        lambda yt, yp: r2_score(np.expm1(yt), np.expm1(yp)),\n",
    "        greater_is_better=True)\n",
    "\n",
    "    search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=group_kfold,\n",
    "        scoring={'r2': r2_scorer, 'rmse': rmse_scorer}, refit='r2',\n",
    "        n_jobs=-1, verbose=1, return_train_score=True)\n",
    "\n",
    "    search.fit(X, y_log, groups=groups)\n",
    "\n",
    "    best = search.best_estimator_\n",
    "    idx = search.best_index_\n",
    "    cv = search.cv_results_\n",
    "\n",
    "    print(f\"\\nBest params: {search.best_params_}\")\n",
    "    print(f\"CV Train R²: {cv['mean_train_r2'][idx]:.4f} | Val R²: {cv['mean_test_r2'][idx]:.4f}\")\n",
    "    print(f\"CV Train RMSE: {-cv['mean_train_rmse'][idx]:.4f} | Val RMSE: {-cv['mean_test_rmse'][idx]:.4f}\")\n",
    "\n",
    "    return best\n",
    "\n",
    "model_TA  = run_pipeline(X, y_TA_log,  groups, \"Total Alkalinity\")\n",
    "model_EC  = run_pipeline(X, y_EC_log,  groups, \"Electrical Conductance\")\n",
    "model_DRP = run_pipeline(X, y_DRP_log, groups, \"Dissolved Reactive Phosphorus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40417c4",
   "metadata": {},
   "source": [
    "## 7. Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c08f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for ax, model, y_log, name in zip(axes,\n",
    "        [model_TA, model_EC, model_DRP],\n",
    "        [y_TA_log, y_EC_log, y_DRP_log],\n",
    "        ['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']):\n",
    "    pi = permutation_importance(model, X, y_log, n_repeats=15, random_state=42, n_jobs=-1)\n",
    "    sorted_idx = pi.importances_mean.argsort()\n",
    "    ax.barh([FEATURE_COLS[i] for i in sorted_idx], pi.importances_mean[sorted_idx])\n",
    "    ax.set_title(name, fontsize=11)\n",
    "    ax.set_xlabel('Mean decrease in score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4fd55a",
   "metadata": {},
   "source": [
    "## 8. Prepare Test Set & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db974fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_test = pd.read_csv(\"landsat_features_validation.csv\")\n",
    "terra_test   = pd.read_csv(\"terraclimate_features_validation.csv\")\n",
    "submission_template = pd.read_csv(\"submission_template.csv\")\n",
    "\n",
    "test = landsat_test.merge(terra_test, on=JOIN_KEYS, how='left')\n",
    "\n",
    "# Same calibration as training\n",
    "test = calibrate_landsat(test)\n",
    "\n",
    "# Cloud filter\n",
    "for col in BANDS:\n",
    "    test[col] = test[col].where(test[col].between(-0.05, 1.2), np.nan)\n",
    "\n",
    "# Impute using TRAINING cluster medians (assign test points to nearest train cluster)\n",
    "test['geo_cluster'] = kmeans.predict(test[['Latitude', 'Longitude']])\n",
    "for col in impute_cols:\n",
    "    cluster_med = df.groupby('geo_cluster')[col].median()\n",
    "    mask = test[col].isna()\n",
    "    test.loc[mask, col] = test.loc[mask, 'geo_cluster'].map(cluster_med)\n",
    "test[impute_cols] = test[impute_cols].fillna(train_medians)\n",
    "\n",
    "# Feature engineering (same as training — no year, no PET lags)\n",
    "dates_t = pd.to_datetime(test['Sample Date'], dayfirst=True)\n",
    "test['month_sin'] = np.sin(2 * np.pi * dates_t.dt.month / 12)\n",
    "test['month_cos'] = np.cos(2 * np.pi * dates_t.dt.month / 12)\n",
    "test['NIR_SWIR22_ratio'] = test['nir'] / (test['swir22'] + 1e-6)\n",
    "test['turbidity']        = test['swir16'] / (test['green'] + 1e-6)\n",
    "\n",
    "X_test = test[FEATURE_COLS]\n",
    "print(f\"Test shape: {X_test.shape}\")\n",
    "\n",
    "# Predict (log-space → original scale)\n",
    "pred_TA  = np.expm1(model_TA.predict(X_test))\n",
    "pred_EC  = np.expm1(model_EC.predict(X_test))\n",
    "pred_DRP = np.expm1(model_DRP.predict(X_test))\n",
    "\n",
    "# Align predictions back to submission_template order\n",
    "test['pred_TA']  = pred_TA\n",
    "test['pred_EC']  = pred_EC\n",
    "test['pred_DRP'] = pred_DRP\n",
    "\n",
    "submission_df = submission_template[JOIN_KEYS].merge(\n",
    "    test[JOIN_KEYS + ['pred_TA', 'pred_EC', 'pred_DRP']], on=JOIN_KEYS, how='left'\n",
    ").rename(columns={\n",
    "    'pred_TA': 'Total Alkalinity',\n",
    "    'pred_EC': 'Electrical Conductance',\n",
    "    'pred_DRP': 'Dissolved Reactive Phosphorus',\n",
    "})\n",
    "\n",
    "display(submission_df.head())\n",
    "print(f\"\\nNaNs in submission: {submission_df.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307db1a4",
   "metadata": {},
   "source": [
    "## 9. Save & Upload Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"/tmp/submission.csv\", index=False)\n",
    "print(\"Saved to /tmp/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "session.sql(\"\"\"\n",
    "    PUT file:///tmp/submission.csv\n",
    "    'snow://workspace/USER$.PUBLIC.\"ey-hackathon\"/versions/live/'\n",
    "    AUTO_COMPRESS=FALSE\n",
    "    OVERWRITE=TRUE\n",
    "\"\"\").collect()\n",
    "print(\"File saved! Refresh the browser to see the files in the sidebar\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
