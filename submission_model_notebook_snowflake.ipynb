{
  "metadata": {},
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2da35050",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# Water Quality Prediction — Submission Notebook"
    },
    {
      "cell_type": "code",
      "id": "6d008edf",
      "metadata": {
        "language": "python"
      },
      "source": "!pip install uv\n!uv pip install -r requirements.txt",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "1dd1c936",
      "metadata": {
        "language": "python"
      },
      "source": "import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nfrom scipy.stats import mstats\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import GroupKFold, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error, make_scorer\nfrom sklearn.inspection import permutation_importance",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "30c2dfb0",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 1. Load & Merge Data (join by key, not by index)"
    },
    {
      "cell_type": "code",
      "id": "30f4ae0e",
      "metadata": {
        "language": "python"
      },
      "source": "wq = pd.read_csv(\"water_quality_training_dataset.csv\")\nlandsat = pd.read_csv(\"landsat_features_training.csv\")\nterra = pd.read_csv(\"terraclimate_features_training.csv\")\n\n# Merge by key — never by index\nJOIN_KEYS = ['Latitude', 'Longitude', 'Sample Date']\ndf = wq.merge(landsat, on=JOIN_KEYS, how='left') \\\n       .merge(terra, on=JOIN_KEYS, how='left')\n\nprint(f\"Shape after merge: {df.shape}\")\ndisplay(df.head())",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "45c1523d",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2. Landsat Calibration (DN → Reflectance) & Recalculate Indices"
    },
    {
      "cell_type": "code",
      "id": "22b64ae5",
      "metadata": {
        "language": "python"
      },
      "source": "BANDS = ['nir', 'green', 'swir16', 'swir22']\n\ndef calibrate_landsat(data):\n    \"\"\"Apply Landsat C2L2 scale/offset to convert DN → surface reflectance.\"\"\"\n    scale, offset = 0.0000275, -0.2\n    for col in BANDS:\n        data[col] = data[col] * scale + offset\n    # Recalculate indices from calibrated reflectance\n    data['NDMI']  = (data['nir'] - data['swir16']) / (data['nir'] + data['swir16'])\n    data['MNDWI'] = (data['green'] - data['swir22']) / (data['green'] + data['swir22'])\n    return data\n\ndf = calibrate_landsat(df)\nprint(\"Calibrated reflectance ranges:\")\nfor b in BANDS:\n    print(f\"  {b}: [{df[b].min():.4f}, {df[b].max():.4f}]\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e15b5e6d",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 3. Cloud Filter, Cluster-based Imputation & DRP Censoring"
    },
    {
      "cell_type": "code",
      "id": "2ee8ff34",
      "metadata": {
        "language": "python"
      },
      "source": "# Cloud filter: after calibration, valid reflectance is roughly [0, 1.0]\nfor col in BANDS:\n    df[col] = df[col].where(df[col].between(-0.05, 1.2), np.nan)\n\n# Cluster-based imputation (spatial, not global median)\nN_CLUSTERS = 8\nkmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init=10)\ndf['geo_cluster'] = kmeans.fit_predict(df[['Latitude', 'Longitude']])\n\nimpute_cols = BANDS + ['NDMI', 'MNDWI', 'pet']\nfor col in impute_cols:\n    cluster_med = df.groupby('geo_cluster')[col].transform('median')\n    df[col] = df[col].fillna(cluster_med)\n# Fallback: global median for any remaining NaN\ntrain_medians = df[impute_cols].median()\ndf[impute_cols] = df[impute_cols].fillna(train_medians)\n\n# DRP censoring: 10.0 = below detection limit → replace with DL/2\ndf['Dissolved Reactive Phosphorus'] = df['Dissolved Reactive Phosphorus'].replace(10.0, 5.0)\n\nprint(f\"Remaining NaNs:\\n{df.isna().sum()[df.isna().sum() > 0]}\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "d64725f5",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 4. Feature Engineering"
    },
    {
      "cell_type": "code",
      "id": "059d9978",
      "metadata": {
        "language": "python"
      },
      "source": "dates = pd.to_datetime(df['Sample Date'], dayfirst=True)\ndf['month_sin'] = np.sin(2 * np.pi * dates.dt.month / 12)\ndf['month_cos'] = np.cos(2 * np.pi * dates.dt.month / 12)\ndf['NIR_SWIR22_ratio'] = df['nir'] / (df['swir22'] + 1e-6)\ndf['turbidity']        = df['swir16'] / (df['green'] + 1e-6)\n\n# KNN is distance-based: year creates artificial distance between identical\n# seasonal patterns and PET lags are mostly copies of pet (first obs fallback),\n# adding redundant dimensions that hurt KNN. Removed both.\nFEATURE_COLS = [\n    'nir', 'green', 'swir16', 'swir22',\n    'NDMI', 'MNDWI',\n    'pet',\n    'month_sin', 'month_cos',\n    'NIR_SWIR22_ratio', 'turbidity',\n]\nprint(f\"Features ({len(FEATURE_COLS)}): {FEATURE_COLS}\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "709338ab",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5. Winsorize Targets & Prepare Training Data"
    },
    {
      "cell_type": "code",
      "id": "d55f6387",
      "metadata": {
        "language": "python"
      },
      "source": "TARGETS = ['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n\n# Winsorize extreme outliers before log transform (critical for KNN — outliers distort distances)\nfor col in TARGETS:\n    df[col] = mstats.winsorize(df[col], limits=[0.01, 0.01])\n\n# Groups for spatial CV\ngroups = df[['Latitude', 'Longitude']].apply(lambda r: f\"{r['Latitude']}_{r['Longitude']}\", axis=1)\n\nX = df[FEATURE_COLS]\ny_TA_log  = np.log1p(df['Total Alkalinity'])\ny_EC_log  = np.log1p(df['Electrical Conductance'])\ny_DRP_log = np.log1p(df['Dissolved Reactive Phosphorus'])\n\nprint(f\"Samples: {len(X)} | Unique locations: {groups.nunique()}\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "d6d2e36d",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 6. Model Training (KNN + StandardScaler + GroupKFold)"
    },
    {
      "cell_type": "code",
      "id": "b96cb571",
      "metadata": {
        "language": "python"
      },
      "source": "def run_pipeline(X, y_log, groups, param_name, n_splits=5):\n    print(f\"\\n{'='*60}\\nTraining: {param_name}\\n{'='*60}\")\n\n    group_kfold = GroupKFold(n_splits=n_splits)\n\n    pipeline = Pipeline([\n        ('scaler', StandardScaler()),\n        ('model', KNeighborsRegressor(weights='distance', metric='euclidean'))\n    ])\n\n    param_grid = {\n        'model__n_neighbors': [5, 7, 10, 15, 20, 30],\n        'model__p': [1, 2],  # 1=manhattan, 2=euclidean\n    }\n\n    rmse_scorer = make_scorer(\n        lambda yt, yp: np.sqrt(mean_squared_error(np.expm1(yt), np.expm1(yp))),\n        greater_is_better=False)\n    r2_scorer = make_scorer(\n        lambda yt, yp: r2_score(np.expm1(yt), np.expm1(yp)),\n        greater_is_better=True)\n\n    search = GridSearchCV(\n        pipeline, param_grid, cv=group_kfold,\n        scoring={'r2': r2_scorer, 'rmse': rmse_scorer}, refit='r2',\n        n_jobs=-1, verbose=1, return_train_score=True)\n\n    search.fit(X, y_log, groups=groups)\n\n    best = search.best_estimator_\n    idx = search.best_index_\n    cv = search.cv_results_\n\n    print(f\"\\nBest params: {search.best_params_}\")\n    print(f\"CV Train R²: {cv['mean_train_r2'][idx]:.4f} | Val R²: {cv['mean_test_r2'][idx]:.4f}\")\n    print(f\"CV Train RMSE: {-cv['mean_train_rmse'][idx]:.4f} | Val RMSE: {-cv['mean_test_rmse'][idx]:.4f}\")\n\n    return best\n\nmodel_TA  = run_pipeline(X, y_TA_log,  groups, \"Total Alkalinity\")\nmodel_EC  = run_pipeline(X, y_EC_log,  groups, \"Electrical Conductance\")\nmodel_DRP = run_pipeline(X, y_DRP_log, groups, \"Dissolved Reactive Phosphorus\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "b40417c4",
      "metadata": {
        "codeCollapsed": true,
        "collapsed": false
      },
      "source": "## 7. Permutation Feature Importance"
    },
    {
      "cell_type": "code",
      "id": "7c08f041",
      "metadata": {
        "language": "python"
      },
      "source": "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\nfor ax, model, y_log, name in zip(axes,\n        [model_TA, model_EC, model_DRP],\n        [y_TA_log, y_EC_log, y_DRP_log],\n        ['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']):\n    pi = permutation_importance(model, X, y_log, n_repeats=15, random_state=42, n_jobs=-1)\n    sorted_idx = pi.importances_mean.argsort()\n    ax.barh([FEATURE_COLS[i] for i in sorted_idx], pi.importances_mean[sorted_idx])\n    ax.set_title(name, fontsize=11)\n    ax.set_xlabel('Mean decrease in score')\nplt.tight_layout()\nplt.show()",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "ff4fd55a",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 8. Prepare Test Set & Predict"
    },
    {
      "cell_type": "code",
      "id": "5db974fd",
      "metadata": {
        "language": "python"
      },
      "source": "landsat_test = pd.read_csv(\"landsat_features_validation.csv\")\nterra_test   = pd.read_csv(\"terraclimate_features_validation.csv\")\nsubmission_template = pd.read_csv(\"submission_template.csv\")\n\ntest = landsat_test.merge(terra_test, on=JOIN_KEYS, how='left')\n\n# Same calibration as training\ntest = calibrate_landsat(test)\n\n# Cloud filter\nfor col in BANDS:\n    test[col] = test[col].where(test[col].between(-0.05, 1.2), np.nan)\n\n# Impute using TRAINING cluster medians (assign test points to nearest train cluster)\ntest['geo_cluster'] = kmeans.predict(test[['Latitude', 'Longitude']])\nfor col in impute_cols:\n    cluster_med = df.groupby('geo_cluster')[col].median()\n    mask = test[col].isna()\n    test.loc[mask, col] = test.loc[mask, 'geo_cluster'].map(cluster_med)\ntest[impute_cols] = test[impute_cols].fillna(train_medians)\n\n# Feature engineering (same as training — no year, no PET lags)\ndates_t = pd.to_datetime(test['Sample Date'], dayfirst=True)\ntest['month_sin'] = np.sin(2 * np.pi * dates_t.dt.month / 12)\ntest['month_cos'] = np.cos(2 * np.pi * dates_t.dt.month / 12)\ntest['NIR_SWIR22_ratio'] = test['nir'] / (test['swir22'] + 1e-6)\ntest['turbidity']        = test['swir16'] / (test['green'] + 1e-6)\n\nX_test = test[FEATURE_COLS]\nprint(f\"Test shape: {X_test.shape}\")\n\n# Predict (log-space → original scale)\npred_TA  = np.expm1(model_TA.predict(X_test))\npred_EC  = np.expm1(model_EC.predict(X_test))\npred_DRP = np.expm1(model_DRP.predict(X_test))\n\n# Align predictions back to submission_template order\ntest['pred_TA']  = pred_TA\ntest['pred_EC']  = pred_EC\ntest['pred_DRP'] = pred_DRP\n\nsubmission_df = submission_template[JOIN_KEYS].merge(\n    test[JOIN_KEYS + ['pred_TA', 'pred_EC', 'pred_DRP']], on=JOIN_KEYS, how='left'\n).rename(columns={\n    'pred_TA': 'Total Alkalinity',\n    'pred_EC': 'Electrical Conductance',\n    'pred_DRP': 'Dissolved Reactive Phosphorus',\n})\n\ndisplay(submission_df.head())\nprint(f\"\\nNaNs in submission: {submission_df.isna().sum().sum()}\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "307db1a4",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 9. Save & Upload Submission"
    },
    {
      "cell_type": "code",
      "id": "6050a26a",
      "metadata": {
        "language": "python"
      },
      "source": "submission_df.to_csv(\"/tmp/submission.csv\", index=False)\nprint(\"Saved to /tmp/submission.csv\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "3e32d89f",
      "metadata": {
        "language": "python"
      },
      "source": "import snowflake\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n\nsession.sql(\"\"\"\n    PUT file:///tmp/submission.csv\n    'snow://workspace/USER$.PUBLIC.\"ey-hackathon\"/versions/live/'\n    AUTO_COMPRESS=FALSE\n    OVERWRITE=TRUE\n\"\"\").collect()\nprint(\"File saved! Refresh the browser to see the files in the sidebar\")",
      "outputs": [],
      "execution_count": null
    }
  ]
}